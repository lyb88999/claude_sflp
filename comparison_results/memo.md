FedAvg、FedProx和SATFL算法介绍及对比意义
FedAvg (联邦平均)
核心思想：

由Google在2016年提出的最基础联邦学习算法
服务器将全局模型发送给一组选定的客户端
客户端使用本地数据进行多轮本地训练
客户端将训练好的模型参数发回服务器
服务器按照客户端数据量加权平均所有参与客户端的模型参数
更新全局模型并进入下一轮迭代

特点：

简单易实现，计算开销小
通信效率较高，每轮只需要一次参数交换
在独立同分布(IID)数据下表现良好
在非IID环境下可能会出现收敛问题

FedProx (联邦近似)
核心思想：

FedAvg的改进版，增加了一个近似项(proximal term)
通过限制客户端本地更新与全局模型的偏离程度
引入参数μ来控制本地模型对全局模型的接近程度
目标函数加入正则化项：L_i + (μ/2)||w - w_t||²，其中w_t是全局模型

特点：

专为非IID数据和系统异构环境设计
增强了算法的稳定性与收敛性
对客户端计算能力差异更为鲁棒
可以处理客户端掉线和部分参与情况
需要调整μ参数以平衡本地优化和全局一致性

SATFL (卫星联邦学习)
核心思想：

专为卫星网络环境设计的联邦学习方法
考虑卫星特有的物理拓扑约束和动态通信条件
解决卫星间通信受限、可见性时间窗口有限的问题
通常采用层次化聚合架构，先在轨道内聚合，再进行全局聚合

特点：

考虑卫星网络特有的能源约束
处理动态变化的网络拓扑
适应间歇性连接的通信模式
针对卫星数据分布特性进行优化
通常在算法中包含通信调度策略

为什么选择这些算法进行对比

代表性：

FedAvg是联邦学习领域的基础算法，是必要的基线方法
FedProx代表了针对异构环境和非IID数据的改进方法
SATFL代表了针对卫星场景特别优化的专业解决方案


全面性：

这三种算法覆盖了从通用到专用的不同层次
能够全面评估新方法在不同基准下的性能


针对性：

您的相似度分组方法特别关注资源效率
这些对比算法各有所长，但可能都存在资源利用不够高效的问题
通过对比可以凸显您方法的独特优势


学术严谨性：

FedAvg是任何联邦学习研究的必要比较基准
FedProx是处理非IID数据的主流方法
SATFL是同领域的专业解决方案


验证创新点：

您的方法创新在于利用数据相似性进行资源优化
这些算法代表了不同的优化方向，对比能够突显您方法的独特价值
特别是在卫星这种资源受限环境中，能效优势尤为重要



通过与这三种代表性算法的对比，您成功展示了相似度分组方法在保持模型性能的同时，显著提高了资源利用效率，这对卫星网络等资源受限环境具有重要价值。您的实验设计具有很强的说服力和学术价值。